
## 16장 스파크 애플리케이션 개발하기


### 16.1 파이썬 애플리케이션 작성하기

```commandline
spark-sumit을 통한 spark 실행
- 명령어 : spark-submit --master local SparkGuide/example/16_1.py
- 관련 코드
from __future__ import print_function

if __name__ == '__main__':
    from pyspark.sql import SparkSession
    spark = SparkSession.builder \
        .master("local") \
        .appName("Word Count") \
        .config("spark.some.config.option", "some-value") \
        .getOrCreate()

    print(spark.range(5000).where("id>500").selectExpr("sum(id)").collect())
```

### 16.2 스파크 애플리케이션 테스트
```commandline
스파크 애플리케이션에서 테스트 해야 할 내용과 테스트 편리성을 높여주는 코드 구성
- 입력 데이터에 대한 유연성
- 비즈니스 로직 변경에 대한 유연성
- 결과의 유연성과 원자성

테스크 코드 작성시 고려사항
- SparkSession 관리하기
    - SparkSession을 한 번만 초기화하고 런타임 환경에서 함수와 클래스에 전달하는 방식을 사용
- 테스트 코드용 스파크 API 선정

단위 테스트 프레임워크 연결하기 
- JUnit 또는 ScalaTst 사용 ( + Pytest )
- 테스트마다 SaprkSession을 생성하고 제거하도록 설정

데이터소스 연결하기
- 운영환경의 데이터소스에 접근 지양
```

### 16.4 애플리케이션 시작하기 
```commandline
실행 커맨트
./bin/spark-submit \
    --class <main class> \
    --master <spark master URL> \
    --deploy-mode <deploy mode> \
    --conf <key>=<value> \
    ... another options
    <Jar file or Script file> \
    [인수 : arg_1, arg_2]
    
예제
./bin/spark-submit \
    --class org.apache.spark.examples.SparkPi \
    --master spark://123.123.123.123:7077 \
    --executor-memory 20G \
    --total-executor-cores 100 \
    replace/with/path/to/examples.jar \
    1000
```

### 16.5 애플리케이션 환경 설정하기
스파크에서는 다음과 같은 방식으로 시스템을 설정
```commandline
SparkConf
- SparkConf 객체는 개별 스파크 애플리케이션에 대한 속성값을 구성하는 용도로 사용
- 예제)
from pyspark import SparkConf
conf = SparkConf()
    .setMaster("local[2]")
    .setAppName("DefinitiveGuide")
    .set("some.conf", "to.some.value")

애플리케이션 속성
- spark.app.name : 사용자 애플리케이션 이름 지정
- spark.driver.cores : 드라이버 프로세스에 사용한 코어수 지정
- spark.driver.maxResultSize : 드라이버 프로세스가 수집할 수 있는 최대 결과 크기
- spark.driver.memory : SparkContext가 초기화되는 드라이버 프로세스에서 사용할 총 메모리
- spark.executor.memory : 각 익스큐터 프로세스에서 사용할 메모리 크기

환경 변수
- 스파크가 설치된 디렉토리의 conf/spark-env.sh 파일에서 설정
- CICD로 버전 관리
```

### 16.5.8 애플리케이션에서 잡 스케줄링
```commandline
- 스파크의 스케줄러는 FIFO 방식으로 동작, 큐의 head에 있는 잡이 클러스터의 전체 자원을 사용하지 않으면 이후 잡을 바로 실행할 수 있음
- 라운드로빈 방식은 모든 잡이 균등하게 자원을 사용할 수 있도록 함
- 페어스케줄러는 더 중요한 스파크 잡을 할당할 수 있도록 우선순위가 높은 풀을 만듬
```