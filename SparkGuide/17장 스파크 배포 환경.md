
## 17장 스파크 배포 환경

```commandline
2017.12월 기준으로 세 가지 클러스터 매니저를 지원
- standalone mode
- hadoop yarn
- apache mesos
```

### 17.1 스파크 애플리케이션 실행을 위한 클러스터 환경

```commandline
설치형 클러스터 (on-premise cluster)
- 사용 중인 하드웨어를 완전히 제어할 수 있으므로 특정 워크로드의 성능을 최적화
- 고정된 자원 
- 자체 파일 저장소( ex.HDFS )를 운영해야하므로 관리포인트가 늘어남
- 자체 파일 저장소를 운영하므로 백업, 가용성 체계도 필요함

공개 클라우드 (public cloud)
- 필요할 때만 자원을 늘리고 줄일 수 있음 ( ex. AWS EMR, EC2 )
- 백업, 복제, 가용성을 자동적으로 지원함
- 파일 저장소를 사용하지 구축하지 않아도 다양한 저장소를 지원함 ( ex.AWS S3 )
```

### 17.2 클러스터 매니저

#### 17.2.1 StandAlone Mode
```commandline
StandAlone Mode
- 경량화 플랫폼
- 하나의 클러스터에서 다수의 스파크 애플리케이션 실행 가능
- 스파크 애플리케이션만 실행 할 수 있음

standalone cluster 실행하기
- $SPARK_HOME/sbin/start-master.sh 명령어 실행
- http://0.0.0.0:8080 에서 마스터 프로세스 UI 확인
- $SPARK_HOME/sbin/start-slave.sh 0.0.0.0:7077 명령어 실행
- start-slave.sh는 conf/slaves 파일에 명시된 각 머신에서 인스턴스를 시작
- spark-submit --master spark://0.0.0.0:7077 SparkGuide/example/16_1.py 로 잡 실행
- spark 결과 확인 - http://0.0.0.0:4040/jobs/ 
```
<br/>

#### 17.2.2 Yarn에서 스파크 실행하기
```commandline
- hadoop yarn은 잡 스케줄링과 클러스터 자원 관리용 프레임워크
- Yarn 설정 파일을 HADOOP_CONF_DIR이나 YARN_CONF_DIR 환경변수를 통해 찾아냄

- 스파크와 HDFS를 연동하려면 hdfs-site.xml, core-site.xml 파일을 class path에 포함시켜야 함
    ㄴ $SPARK_HOME/spark-env.sh 파일의 HADOOP_CONF_DIR 변수값을 하툽 설정 파일 경로로 지정
```
<br/>

#### 17.2.7 애플리케이션 스케줄링
```commandline
- 스케줄러: 스케줄러는 클러스터 매니저에 의해 제공되는 리소스를 사용하여 스파크 애플리케이션의 작업을 실행하는 방법을 결정
- FIFO, Capacity Scheduler와 Fair Scheduler를 사용하여 다양한 스케줄링 정책을 구현할 수 있음
- 큐: 스케줄러는 여러 큐를 사용하여 작업을 관리하고 우선 순위를 지정, 각 큐에는 작업이 실행되기를 대기하는 리소스가 할당 
- 리소스 할당: 각 애플리케이션에는 실행할 때 필요한 CPU, 메모리 및 기타 리소스가 필요하며 스케줄러가 클러스터 내에서 할당 작업을 실행
```
